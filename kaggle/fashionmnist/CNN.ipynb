{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40a76bbe-ca38-4f20-9947-2cbb38c72cf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a7d749d-a6e0-49af-8996-d342cc58f3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('./input/fashion-mnist/fashion-mnist_train.csv')\n",
    "test = pd.read_csv('./input/fashion-mnist/fashion-mnist_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82f8bfe5-ee91-490d-b666-d430aafc1a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train.copy()\n",
    "\n",
    "train = df.sample(frac = 0.7, random_state = 0)\n",
    "valid = df.drop(train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c563e7c5-1f20-4207-b7df-ddb4609204e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_feature_label(df):\n",
    "    X = df.copy()\n",
    "    y = X.pop('label')\n",
    "    return X, y\n",
    "    \n",
    "X_train, y_train = split_feature_label(train)\n",
    "X_valid, y_valid = split_feature_label(valid)\n",
    "X_test, y_test = split_feature_label(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8ca02f1-7713-493b-8918-766321b7182b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pixel1       0\n",
       "pixel2       0\n",
       "pixel3       0\n",
       "pixel4       0\n",
       "pixel5       0\n",
       "pixel6       0\n",
       "pixel7       0\n",
       "pixel8       0\n",
       "pixel9       0\n",
       "pixel10      0\n",
       "pixel11     41\n",
       "pixel12    120\n",
       "pixel13    128\n",
       "pixel14    127\n",
       "pixel15    121\n",
       "Name: 3048, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.iloc[0][0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dd1624c-fa0a-4b9e-ba57-0b5a69595040",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40cc2e65-9dd1-4c78-aef4-3440dfa98c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pixel1     0.000000\n",
       "pixel2     0.000000\n",
       "pixel3     0.000000\n",
       "pixel4     0.000000\n",
       "pixel5     0.000000\n",
       "pixel6     0.000000\n",
       "pixel7     0.000000\n",
       "pixel8     0.000000\n",
       "pixel9     0.000000\n",
       "pixel10    0.000000\n",
       "pixel11    0.160784\n",
       "pixel12    0.470588\n",
       "pixel13    0.501961\n",
       "pixel14    0.498039\n",
       "pixel15    0.474510\n",
       "Name: 3048, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.iloc[0][0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34567fa7-fb17-4ef2-9590-b1e55002f911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7380d980-8ea9-4516-b547-1d9fb0cb928a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid /= 255.0\n",
    "X_test /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "223e9b16-5e13-4c26-a164-0d859b1d7a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import callbacks\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    patience = 5,\n",
    "    min_delta = 0.001,\n",
    "    restore_best_weights = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6f9a56f-945b-4928-adcb-f1a898e2abab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nmodel = keras.Sequential([\\n    layers.Reshape((28, 28, 1), input_shape = (784, )),\\n    layers.Conv2D(32, (3, 3), padding = 'same', activation = 'relu'),\\n    layers.MaxPool2D((2, 2), strides = 2),\\n    layers.Flatten(),\\n    layers.Dense(128, activation = 'relu'),\\n    layers.Dense(10, activation = 'softmax'),\\n])\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# val_accuracy: 0.9167\n",
    "\"\"\"\n",
    "model = keras.Sequential([\n",
    "    layers.Reshape((28, 28, 1), input_shape = (784, )),\n",
    "    layers.Conv2D(32, (3, 3), padding = 'same', activation = 'relu'),\n",
    "    layers.MaxPool2D((2, 2), strides = 2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation = 'relu'),\n",
    "    layers.Dense(10, activation = 'softmax'),\n",
    "])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f66c6369-4f11-4478-b134-ba4eb0f9b3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "165/165 [==============================] - 14s 83ms/step - loss: 0.7415 - accuracy: 0.7302 - val_loss: 0.4564 - val_accuracy: 0.8344\n",
      "Epoch 2/500\n",
      "165/165 [==============================] - 14s 84ms/step - loss: 0.4591 - accuracy: 0.8321 - val_loss: 0.3910 - val_accuracy: 0.8581\n",
      "Epoch 3/500\n",
      "165/165 [==============================] - 13s 81ms/step - loss: 0.4061 - accuracy: 0.8546 - val_loss: 0.3431 - val_accuracy: 0.8755\n",
      "Epoch 4/500\n",
      "165/165 [==============================] - 14s 82ms/step - loss: 0.3700 - accuracy: 0.8654 - val_loss: 0.3167 - val_accuracy: 0.8829\n",
      "Epoch 5/500\n",
      "165/165 [==============================] - 14s 87ms/step - loss: 0.3454 - accuracy: 0.8742 - val_loss: 0.3082 - val_accuracy: 0.8856\n",
      "Epoch 6/500\n",
      "165/165 [==============================] - 16s 96ms/step - loss: 0.3299 - accuracy: 0.8792 - val_loss: 0.2898 - val_accuracy: 0.8939\n",
      "Epoch 7/500\n",
      "165/165 [==============================] - 15s 93ms/step - loss: 0.3084 - accuracy: 0.8870 - val_loss: 0.2825 - val_accuracy: 0.8963\n",
      "Epoch 8/500\n",
      "165/165 [==============================] - 16s 98ms/step - loss: 0.2998 - accuracy: 0.8917 - val_loss: 0.3004 - val_accuracy: 0.8889\n",
      "Epoch 9/500\n",
      "165/165 [==============================] - 15s 94ms/step - loss: 0.2928 - accuracy: 0.8912 - val_loss: 0.2628 - val_accuracy: 0.9032\n",
      "Epoch 10/500\n",
      "165/165 [==============================] - 15s 92ms/step - loss: 0.2754 - accuracy: 0.8994 - val_loss: 0.2504 - val_accuracy: 0.9089\n",
      "Epoch 11/500\n",
      "165/165 [==============================] - 16s 96ms/step - loss: 0.2657 - accuracy: 0.9025 - val_loss: 0.2497 - val_accuracy: 0.9079\n",
      "Epoch 12/500\n",
      "165/165 [==============================] - 16s 96ms/step - loss: 0.2586 - accuracy: 0.9043 - val_loss: 0.2449 - val_accuracy: 0.9106\n",
      "Epoch 13/500\n",
      "165/165 [==============================] - 16s 95ms/step - loss: 0.2513 - accuracy: 0.9076 - val_loss: 0.2433 - val_accuracy: 0.9099\n",
      "Epoch 14/500\n",
      "165/165 [==============================] - 16s 96ms/step - loss: 0.2506 - accuracy: 0.9067 - val_loss: 0.2341 - val_accuracy: 0.9148\n",
      "Epoch 15/500\n",
      "165/165 [==============================] - 16s 95ms/step - loss: 0.2357 - accuracy: 0.9143 - val_loss: 0.2295 - val_accuracy: 0.9145\n",
      "Epoch 16/500\n",
      "165/165 [==============================] - 16s 96ms/step - loss: 0.2298 - accuracy: 0.9150 - val_loss: 0.2290 - val_accuracy: 0.9158\n",
      "Epoch 17/500\n",
      "165/165 [==============================] - 16s 96ms/step - loss: 0.2303 - accuracy: 0.9143 - val_loss: 0.2273 - val_accuracy: 0.9169\n",
      "Epoch 18/500\n",
      "165/165 [==============================] - 16s 95ms/step - loss: 0.2226 - accuracy: 0.9188 - val_loss: 0.2250 - val_accuracy: 0.9173\n",
      "Epoch 19/500\n",
      "165/165 [==============================] - 16s 96ms/step - loss: 0.2163 - accuracy: 0.9194 - val_loss: 0.2211 - val_accuracy: 0.9183\n",
      "Epoch 20/500\n",
      "165/165 [==============================] - 17s 100ms/step - loss: 0.2117 - accuracy: 0.9212 - val_loss: 0.2162 - val_accuracy: 0.9227\n",
      "Epoch 21/500\n",
      "165/165 [==============================] - 16s 98ms/step - loss: 0.2067 - accuracy: 0.9210 - val_loss: 0.2171 - val_accuracy: 0.9204\n",
      "Epoch 22/500\n",
      "165/165 [==============================] - 17s 100ms/step - loss: 0.2030 - accuracy: 0.9239 - val_loss: 0.2177 - val_accuracy: 0.9207\n",
      "Epoch 23/500\n",
      "165/165 [==============================] - 15s 91ms/step - loss: 0.1996 - accuracy: 0.9257 - val_loss: 0.2161 - val_accuracy: 0.9232\n",
      "Epoch 24/500\n",
      "165/165 [==============================] - 16s 94ms/step - loss: 0.1930 - accuracy: 0.9268 - val_loss: 0.2134 - val_accuracy: 0.9227\n",
      "Epoch 25/500\n",
      "165/165 [==============================] - 16s 94ms/step - loss: 0.1890 - accuracy: 0.9283 - val_loss: 0.2148 - val_accuracy: 0.9216\n",
      "Epoch 26/500\n",
      "165/165 [==============================] - 15s 93ms/step - loss: 0.1852 - accuracy: 0.9315 - val_loss: 0.2081 - val_accuracy: 0.9254\n",
      "Epoch 27/500\n",
      "165/165 [==============================] - 16s 94ms/step - loss: 0.1837 - accuracy: 0.9310 - val_loss: 0.2098 - val_accuracy: 0.9246\n",
      "Epoch 28/500\n",
      "165/165 [==============================] - 16s 98ms/step - loss: 0.1809 - accuracy: 0.9320 - val_loss: 0.2054 - val_accuracy: 0.9270\n",
      "Epoch 29/500\n",
      "165/165 [==============================] - 16s 95ms/step - loss: 0.1765 - accuracy: 0.9329 - val_loss: 0.2071 - val_accuracy: 0.9264\n",
      "Epoch 30/500\n",
      "165/165 [==============================] - 16s 95ms/step - loss: 0.1784 - accuracy: 0.9325 - val_loss: 0.2069 - val_accuracy: 0.9259\n",
      "Epoch 31/500\n",
      "165/165 [==============================] - 16s 95ms/step - loss: 0.1688 - accuracy: 0.9358 - val_loss: 0.2037 - val_accuracy: 0.9282\n",
      "Epoch 32/500\n",
      "165/165 [==============================] - 16s 98ms/step - loss: 0.1688 - accuracy: 0.9357 - val_loss: 0.2022 - val_accuracy: 0.9286\n",
      "Epoch 33/500\n",
      "165/165 [==============================] - 15s 94ms/step - loss: 0.1658 - accuracy: 0.9376 - val_loss: 0.2037 - val_accuracy: 0.9289\n",
      "Epoch 34/500\n",
      "165/165 [==============================] - 16s 97ms/step - loss: 0.1624 - accuracy: 0.9368 - val_loss: 0.2180 - val_accuracy: 0.9244\n",
      "Epoch 35/500\n",
      "165/165 [==============================] - 15s 93ms/step - loss: 0.1634 - accuracy: 0.9384 - val_loss: 0.2044 - val_accuracy: 0.9266\n",
      "Epoch 36/500\n",
      "165/165 [==============================] - 16s 97ms/step - loss: 0.1575 - accuracy: 0.9409 - val_loss: 0.2067 - val_accuracy: 0.9278\n",
      "Epoch 37/500\n",
      "165/165 [==============================] - 16s 95ms/step - loss: 0.1546 - accuracy: 0.9409 - val_loss: 0.2029 - val_accuracy: 0.9285\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Reshape((28, 28, 1), input_shape = (784, )),\n",
    "    \n",
    "    layers.Conv2D(32, (3, 3), padding = 'same', activation = 'relu'),\n",
    "    layers.MaxPool2D((2, 2), strides = 2),\n",
    "    layers.Dropout(0.3),\n",
    "    \n",
    "    layers.Conv2D(64, (3, 3), padding = 'same', activation = 'relu'),\n",
    "    layers.MaxPool2D((2, 2), strides = 2),\n",
    "    layers.Dropout(0.3),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    \n",
    "    layers.Dense(128, activation = 'relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    \n",
    "    layers.Dense(10, activation = 'softmax'),\n",
    "])\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data = (X_valid, y_valid),\n",
    "    batch_size = 256,\n",
    "    epochs = 500,\n",
    "    callbacks = [early_stopping],\n",
    "#    verbose = 0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "381dfef5-4949-4c19-aa2d-56a2f67d959f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92894446849823"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(history.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d476e4f-ba3e-4c42-a22b-bd884443b73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 9ms/step - loss: 0.1971 - accuracy: 0.9271\n",
      "Test loss: 0.19712169468402863, Test accuracy: 0.9271000027656555\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test loss: {test_loss}, Test accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e90b8b-24ec-4646-8ee6-724f60596e01",
   "metadata": {},
   "source": [
    "# Reference\n",
    "\n",
    "[Kaggle - Intro to Deep Learning - Dropout and Batch Normalization](https://www.kaggle.com/ryanholbrook/dropout-and-batch-normalization)\n",
    "\n",
    "[UD187 - Lession 4: Introduction to CNNs Colab](https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l04c01_image_classification_with_cnns.ipynb#scrollTo=9ODch-OFCaW4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
